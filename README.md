# ğŸ“Š Multivariate Convolutional Regression

<div align="center">

**A powerful Temporal Convolutional Network (TCN) library for multivariate time
series regression with online learning capabilities**

[ğŸ“¦ JSR Package](https://jsr.io/@hviana/multivariate-convolutional-regression) â€¢
[ğŸ™ GitHub](https://github.com/hviana/multivariate-convolutional-regression) â€¢
[ğŸ“– Documentation](#-table-of-contents)

</div>

---

## ğŸ“‘ Table of Contents

- [âœ¨ Features](#-features)
- [ğŸš€ Installation](#-installation)
- [âš¡ Quick Start](#-quick-start)
- [ğŸ—ï¸ Architecture](#ï¸-architecture)
- [ğŸ“š API Reference](#-api-reference)
- [âš™ï¸ Configuration Parameters](#ï¸-configuration-parameters)
- [ğŸ¯ Optimization Guide](#-optimization-guide)
- [ğŸ“ˆ Use Case Examples](#-use-case-examples)
- [ğŸ§® Mathematical Foundations](#-mathematical-foundations)
- [ğŸ’¾ Serialization](#-serialization)
- [ğŸ¤ Contributing](#-contributing)
- [ğŸ“„ License](#-license)

---

## âœ¨ Features

<table>
<tr>
<td width="50%">

### ğŸ§  Deep Learning Architecture

- **Temporal Convolutional Networks** with dilated causal convolutions
- **Residual connections** for gradient flow
- **Multi-horizon prediction** (direct or recursive)
- Configurable **activation functions** (ReLU/GELU)
- Optional **Layer Normalization**

</td>
<td width="50%">

### ğŸ“¡ Online Learning

- **Single-sample training** (streaming data)
- **Welford algorithm** for running statistics
- **ADWIN drift detection** for concept drift
- **Outlier downweighting** for robustness
- No mini-batching required

</td>
</tr>
<tr>
<td width="50%">

### ğŸ›ï¸ Advanced Optimization

- **Adam optimizer** with bias correction
- **L2 regularization** (weight decay)
- **Gradient clipping** by norm
- Automatic **z-score normalization**
- Xavier/He weight initialization

</td>
<td width="50%">

### ğŸ“Š Uncertainty Quantification

- **Prediction confidence intervals**
- **Residual-based uncertainty** estimation
- Configurable **confidence multiplier**
- Growing uncertainty for longer horizons

</td>
</tr>
</table>

### ğŸ¯ Key Highlights

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  âœ… Zero Dependencies        â”‚  âœ… TypeScript Native    â”‚  âœ… Memory Efficient â”‚
â”‚  âœ… Streaming Compatible     â”‚  âœ… Auto-normalization   â”‚  âœ… Drift Detection  â”‚
â”‚  âœ… Serializable             â”‚  âœ… Multi-target Support â”‚  âœ… Configurable     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Installation

### Deno

```typescript
import { ConvolutionalRegression } from "jsr:@hviana/multivariate-convolutional-regression";
```

### Node.js (via JSR)

```bash
npx jsr add @hviana/multivariate-convolutional-regression
```

```typescript
import { ConvolutionalRegression } from "@hviana/multivariate-convolutional-regression";
```

---

## âš¡ Quick Start

### Basic Example

```typescript
import { ConvolutionalRegression } from "jsr:@hviana/multivariate-convolutional-regression";

// ğŸ”§ Create model with default configuration
const model = new ConvolutionalRegression({
  maxSequenceLength: 32,
  hiddenChannels: 16,
  nBlocks: 3,
});

// ğŸ“Š Training data: predict y from x over time
const trainingData = [
  { x: [1.0, 2.0], y: [0.5] },
  { x: [1.2, 2.1], y: [0.52] },
  { x: [1.4, 2.3], y: [0.55] },
  // ... more timesteps
];

// ğŸ¯ Train online (one sample at a time)
for (const sample of trainingData) {
  const result = model.fitOnline({
    xCoordinates: [sample.x],
    yCoordinates: [sample.y],
  });

  console.log(`ğŸ“‰ Loss: ${result.loss.toFixed(4)}`);
}

// ğŸ”® Make predictions
const prediction = model.predict(3); // Predict 3 steps ahead
console.log("Predictions:", prediction.predictions);
console.log("Confidence:", prediction.confidence);
```

---

## ğŸ—ï¸ Architecture

### Network Overview

```
                           TCN ARCHITECTURE DIAGRAM
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                             â”‚
â”‚   INPUT SEQUENCE                    TCN BACKBONE                   OUTPUT   â”‚
â”‚   [T Ã— Features]                   (Residual Blocks)              [Targets] â”‚
â”‚                                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚ t â”‚ t â”‚ t â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚    â”‚         â”‚  â”‚
â”‚   â”‚ 1 â”‚ 2 â”‚...â”‚â”€â”€â”€â–¶â”‚  â”‚ Block 1 â”‚â”€â”€â–¶â”‚ Block 2 â”‚â”€â”€â–¶ ... â”€â”€â”‚â”€â”€â”€â–¶â”‚  Head   â”‚  â”‚
â”‚   â”‚   â”‚   â”‚   â”‚    â”‚  â”‚ d=1     â”‚   â”‚ d=2     â”‚   d=2^n  â”‚    â”‚         â”‚  â”‚
â”‚   â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜    â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜          â”‚    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â”‚
â”‚                    â”‚       â”‚             â”‚               â”‚         â”‚       â”‚
â”‚                    â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚         â–¼       â”‚
â”‚                    â”‚           (Residual Connections)    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚yâ‚ yâ‚‚ ...â”‚   â”‚
â”‚                                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### TCN Block Detail

```
                              TCN RESIDUAL BLOCK
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                          â”‚
â”‚     Input                                                                â”‚
â”‚       â”‚                                                                  â”‚
â”‚       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚       â”‚                                             â”‚                    â”‚
â”‚       â–¼                                             â”‚ (Residual)         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚                    â”‚
â”‚  â”‚ Causal Conv â”‚  Dilated, kernel_size=k            â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                    â”‚                    â”‚
â”‚         â”‚                                           â”‚                    â”‚
â”‚         â–¼                                           â”‚                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚                    â”‚
â”‚  â”‚ Activation  â”‚  ReLU or GELU                      â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                    â”‚                    â”‚
â”‚         â”‚                                           â”‚                    â”‚
â”‚         â–¼ (if useTwoLayerBlock)                     â”‚                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚                    â”‚
â”‚  â”‚ Causal Conv â”‚                                    â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                    â”‚                    â”‚
â”‚         â”‚                                           â”‚                    â”‚
â”‚         â–¼                                           â–¼                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ Activation  â”‚                            â”‚  1Ã—1 Conv   â”‚ (if needed)  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚         â”‚                                          â”‚                    â”‚
â”‚         â–¼ (optional)                               â”‚                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚                    â”‚
â”‚  â”‚ Layer Norm  â”‚                                   â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                   â”‚                    â”‚
â”‚         â”‚                                          â”‚                    â”‚
â”‚         â–¼ (optional)                               â”‚                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚                    â”‚
â”‚  â”‚   Dropout   â”‚                                   â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                   â”‚                    â”‚
â”‚         â”‚                                          â”‚                    â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                            â”‚                                            â”‚
â”‚                            â–¼                                            â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                     â”‚
â”‚                     â”‚     ADD     â”‚                                     â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                     â”‚
â”‚                            â”‚                                            â”‚
â”‚                            â–¼                                            â”‚
â”‚                         Output                                          â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Causal Dilated Convolution

```
    RECEPTIVE FIELD WITH DILATION
    
Dilation = 1    Dilation = 2    Dilation = 4

     â—               â—               â—          Output
    /|\             /|\             /|\
   / | \           / | \           / | \
  â—  â—  â—         â—  â—  â—         â—  â—  â—       Hidden
  â”‚  â”‚  â”‚         â”‚     â”‚         â”‚           â”‚
  â”‚  â”‚  â”‚         â”‚     â”‚         â”‚           â”‚
  â—  â—  â—  â—      â—  â—  â—  â—      â—  â—  â—  â—  â—  â—  â—  â—  Input
  t-2 t-1 t       t-4 t-2 t       t-8 t-4 t
  
Receptive Field = Î£(kernel_size - 1) Ã— dilation + 1
```

### Data Flow Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           DATA FLOW PIPELINE                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  Raw Input    Normalize     Ring Buffer    TCN Forward    Denormalize      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶     â”‚
â”‚   [x, y]       z-score      Sequence       Features       Predictions      â”‚
â”‚              (Welford)      History        Extraction                       â”‚
â”‚                                                                             â”‚
â”‚                              â”‚                                              â”‚
â”‚                              â–¼                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                     TRAINING PATH (fitOnline)                        â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚   Compute Loss â”€â”€â–¶ Outlier Weight â”€â”€â–¶ Backward Pass â”€â”€â–¶ Adam Step   â”‚   â”‚
â”‚  â”‚        â”‚                                      â”‚             â”‚        â”‚   â”‚
â”‚  â”‚        â–¼                                      â–¼             â–¼        â”‚   â”‚
â”‚  â”‚   ADWIN Drift                          Gradient Clip    Update       â”‚   â”‚
â”‚  â”‚   Detection                            by Norm          Moments      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“š API Reference

### Constructor

```typescript
const model = new ConvolutionalRegression(config?: TCNRegressionConfig);
```

### Methods

| Method                    | Description             | Returns              |
| ------------------------- | ----------------------- | -------------------- |
| `fitOnline(data)`         | Train on single sample  | `FitResult`          |
| `predict(futureSteps?)`   | Generate predictions    | `PredictionResult`   |
| `getModelSummary()`       | Get architecture info   | `ModelSummary`       |
| `getWeights()`            | Inspect parameters      | `WeightInfo`         |
| `getNormalizationStats()` | Get normalization state | `NormalizationStats` |
| `reset()`                 | Reset to initial state  | `void`               |
| `save()`                  | Serialize model         | `string`             |
| `load(json)`              | Deserialize model       | `void`               |

### Type Definitions

#### FitResult

```typescript
interface FitResult {
  loss: number; // MSE loss for this sample
  sampleWeight: number; // Applied sample weight (outlier handling)
  driftDetected: boolean; // Whether ADWIN detected drift
  metrics: {
    avgLoss: number; // Running average loss
    mae: number; // Mean absolute error
    sampleCount: number; // Total samples processed
  };
}
```

#### PredictionResult

```typescript
interface PredictionResult {
  predictions: number[][]; // [futureSteps][nTargets]
  uncertaintyLower: number[][]; // Lower confidence bounds
  uncertaintyUpper: number[][]; // Upper confidence bounds
  confidence: number; // 0-1 confidence score
}
```

#### ModelSummary

```typescript
interface ModelSummary {
  architecture: string; // Human-readable description
  layerParams: { [name: string]: number };
  totalParams: number;
  receptiveField: number; // Timesteps the model can "see"
  memoryBytes: number; // Estimated memory usage
  nFeatures: number;
  nTargets: number;
  sampleCount: number;
}
```

---

## âš™ï¸ Configuration Parameters

### ğŸ›ï¸ Architecture Parameters

<table>
<tr>
<th>Parameter</th>
<th>Type</th>
<th>Default</th>
<th>Description</th>
</tr>
<tr>
<td><code>maxSequenceLength</code></td>
<td>number</td>
<td>64</td>
<td>Maximum lookback window (receptive field cap). Determines how many past timesteps the model can consider.</td>
</tr>
<tr>
<td><code>maxFutureSteps</code></td>
<td>number</td>
<td>1</td>
<td>Maximum prediction horizon. Set higher for multi-step forecasting.</td>
</tr>
<tr>
<td><code>hiddenChannels</code></td>
<td>number</td>
<td>32</td>
<td>Number of channels in TCN blocks. Higher = more capacity, more compute.</td>
</tr>
<tr>
<td><code>nBlocks</code></td>
<td>number</td>
<td>4</td>
<td>Number of residual TCN blocks. More blocks = larger receptive field.</td>
</tr>
<tr>
<td><code>kernelSize</code></td>
<td>number</td>
<td>3</td>
<td>Convolution kernel size. Larger kernels capture longer local patterns.</td>
</tr>
<tr>
<td><code>dilationBase</code></td>
<td>number</td>
<td>2</td>
<td>Dilation growth factor. Dilations = base^blockIndex (1, 2, 4, 8...).</td>
</tr>
<tr>
<td><code>useTwoLayerBlock</code></td>
<td>boolean</td>
<td>true</td>
<td>Use 2 conv layers per TCN block for increased expressiveness.</td>
</tr>
<tr>
<td><code>useDirectMultiHorizon</code></td>
<td>boolean</td>
<td>true</td>
<td>Direct multi-step prediction vs recursive rollforward.</td>
</tr>
</table>

#### ğŸ“ Receptive Field Formula

```
Receptive Field = 1 + Î£áµ¢ (kernelSize - 1) Ã— dilationBase^i Ã— layersPerBlock

Example (defaults):
  nBlocks=4, kernelSize=3, dilationBase=2, useTwoLayerBlock=true
  RF = 1 + 2Ã—(2Ã—1 + 2Ã—2 + 2Ã—4 + 2Ã—8) = 1 + 2Ã—30 = 61 timesteps
```

### ğŸ›ï¸ Activation & Normalization

<table>
<tr>
<th>Parameter</th>
<th>Type</th>
<th>Default</th>
<th>Description</th>
</tr>
<tr>
<td><code>activation</code></td>
<td>"relu" | "gelu"</td>
<td>"relu"</td>
<td>Activation function. GELU is smoother but more expensive.</td>
</tr>
<tr>
<td><code>useLayerNorm</code></td>
<td>boolean</td>
<td>false</td>
<td>Enable channel normalization after convolutions. Helps with deep networks.</td>
</tr>
<tr>
<td><code>dropoutRate</code></td>
<td>number</td>
<td>0.0</td>
<td>Dropout probability during training (0.0 - 1.0).</td>
</tr>
</table>

### ğŸ“ˆ Optimizer Parameters

<table>
<tr>
<th>Parameter</th>
<th>Type</th>
<th>Default</th>
<th>Description</th>
</tr>
<tr>
<td><code>learningRate</code></td>
<td>number</td>
<td>0.001</td>
<td>Adam learning rate. Lower for stability, higher for speed.</td>
</tr>
<tr>
<td><code>beta1</code></td>
<td>number</td>
<td>0.9</td>
<td>Adam first moment decay (momentum).</td>
</tr>
<tr>
<td><code>beta2</code></td>
<td>number</td>
<td>0.999</td>
<td>Adam second moment decay (adaptive learning).</td>
</tr>
<tr>
<td><code>epsilon</code></td>
<td>number</td>
<td>1e-8</td>
<td>Adam numerical stability constant.</td>
</tr>
<tr>
<td><code>l2Lambda</code></td>
<td>number</td>
<td>0.0001</td>
<td>L2 regularization coefficient (weight decay).</td>
</tr>
<tr>
<td><code>gradientClipNorm</code></td>
<td>number</td>
<td>1.0</td>
<td>Maximum gradient L2 norm to prevent exploding gradients.</td>
</tr>
</table>

### ğŸ“Š Normalization Parameters

<table>
<tr>
<th>Parameter</th>
<th>Type</th>
<th>Default</th>
<th>Description</th>
</tr>
<tr>
<td><code>normalizationEpsilon</code></td>
<td>number</td>
<td>1e-8</td>
<td>Variance floor for numerical stability.</td>
</tr>
<tr>
<td><code>normalizationWarmup</code></td>
<td>number</td>
<td>10</td>
<td>Samples before applying z-score normalization.</td>
</tr>
</table>

### ğŸ›¡ï¸ Robustness Parameters

<table>
<tr>
<th>Parameter</th>
<th>Type</th>
<th>Default</th>
<th>Description</th>
</tr>
<tr>
<td><code>outlierThreshold</code></td>
<td>number</td>
<td>3.0</td>
<td>Z-score threshold for outlier detection.</td>
</tr>
<tr>
<td><code>outlierMinWeight</code></td>
<td>number</td>
<td>0.1</td>
<td>Minimum sample weight for outliers (0.0-1.0).</td>
</tr>
<tr>
<td><code>adwinEnabled</code></td>
<td>boolean</td>
<td>true</td>
<td>Enable ADWIN drift detection.</td>
</tr>
<tr>
<td><code>adwinDelta</code></td>
<td>number</td>
<td>0.002</td>
<td>ADWIN significance parameter. Lower = more sensitive.</td>
</tr>
<tr>
<td><code>adwinMaxBuckets</code></td>
<td>number</td>
<td>64</td>
<td>Maximum ADWIN bucket count (memory limit).</td>
</tr>
</table>

### ğŸ“‰ Uncertainty Parameters

<table>
<tr>
<th>Parameter</th>
<th>Type</th>
<th>Default</th>
<th>Description</th>
</tr>
<tr>
<td><code>residualWindowSize</code></td>
<td>number</td>
<td>100</td>
<td>Number of recent residuals for uncertainty estimation.</td>
</tr>
<tr>
<td><code>uncertaintyMultiplier</code></td>
<td>number</td>
<td>1.96</td>
<td>Z-multiplier for confidence bounds (1.96 â‰ˆ 95%).</td>
</tr>
</table>

### ğŸ”§ Misc Parameters

<table>
<tr>
<th>Parameter</th>
<th>Type</th>
<th>Default</th>
<th>Description</th>
</tr>
<tr>
<td><code>weightInitScale</code></td>
<td>number</td>
<td>0.1</td>
<td>Xavier/He initialization scale factor.</td>
</tr>
<tr>
<td><code>seed</code></td>
<td>number</td>
<td>42</td>
<td>Deterministic RNG seed for reproducibility.</td>
</tr>
<tr>
<td><code>verbose</code></td>
<td>boolean</td>
<td>false</td>
<td>Enable debug logging.</td>
</tr>
</table>

---

## ğŸ¯ Optimization Guide

### ğŸ“Š By Data Characteristics

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      PARAMETER SELECTION GUIDE                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  DATA TYPE              RECOMMENDED SETTINGS                                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€              â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                â”‚
â”‚                                                                             â”‚
â”‚  ğŸ”„ Fast-changing       maxSequenceLength: 16-32                            â”‚
â”‚     (high frequency)    nBlocks: 2-3                                        â”‚
â”‚                         learningRate: 0.005-0.01                            â”‚
â”‚                                                                             â”‚
â”‚  ğŸ“ˆ Slow trends         maxSequenceLength: 128-256                          â”‚
â”‚     (seasonal)          nBlocks: 5-6                                        â”‚
â”‚                         dilationBase: 2-3                                   â”‚
â”‚                                                                             â”‚
â”‚  ğŸŒŠ Noisy data          useLayerNorm: true                                  â”‚
â”‚                         dropoutRate: 0.1-0.2                                â”‚
â”‚                         l2Lambda: 0.001                                     â”‚
â”‚                         outlierThreshold: 2.0                               â”‚
â”‚                                                                             â”‚
â”‚  ğŸ¯ High precision      hiddenChannels: 64-128                              â”‚
â”‚     needed              useTwoLayerBlock: true                              â”‚
â”‚                         activation: "gelu"                                  â”‚
â”‚                                                                             â”‚
â”‚  âš¡ Limited memory      hiddenChannels: 8-16                                â”‚
â”‚                         nBlocks: 2                                          â”‚
â”‚                         useTwoLayerBlock: false                             â”‚
â”‚                                                                             â”‚
â”‚  ğŸ”€ Concept drift       adwinEnabled: true                                  â”‚
â”‚     expected            adwinDelta: 0.001                                   â”‚
â”‚                         learningRate: 0.003                                 â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸšï¸ Configuration Presets

#### ğŸƒ Fast & Light (Edge/IoT)

```typescript
const lightConfig = {
  maxSequenceLength: 16,
  hiddenChannels: 8,
  nBlocks: 2,
  kernelSize: 2,
  useTwoLayerBlock: false,
  useLayerNorm: false,
  learningRate: 0.01,
};
```

#### âš–ï¸ Balanced (General Purpose)

```typescript
const balancedConfig = {
  maxSequenceLength: 64,
  hiddenChannels: 32,
  nBlocks: 4,
  kernelSize: 3,
  useTwoLayerBlock: true,
  activation: "relu",
  learningRate: 0.001,
};
```

#### ğŸ¯ High Accuracy (Maximum Performance)

```typescript
const accurateConfig = {
  maxSequenceLength: 128,
  hiddenChannels: 64,
  nBlocks: 6,
  kernelSize: 3,
  useTwoLayerBlock: true,
  activation: "gelu",
  useLayerNorm: true,
  dropoutRate: 0.1,
  learningRate: 0.0005,
};
```

#### ğŸ”€ Adaptive (Non-stationary Data)

```typescript
const adaptiveConfig = {
  maxSequenceLength: 32,
  hiddenChannels: 32,
  nBlocks: 3,
  adwinEnabled: true,
  adwinDelta: 0.001,
  learningRate: 0.003,
  outlierThreshold: 2.5,
  residualWindowSize: 50,
};
```

### ğŸ“ˆ Tuning Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     HYPERPARAMETER TUNING FLOW                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Start with defaults  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”‚   Loss decreasing?    â”‚â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ NO    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ YES   â”‚
            â”‚                                       â”‚
            â–¼                                       â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ â†‘ learningRateâ”‚                   â”‚ Loss plateaued?   â”‚
    â”‚ or            â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚ â†‘ hiddenChan  â”‚                       â”‚         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    NO â”‚         â”‚ YES
                                            â–¼         â–¼
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚ Continueâ”‚   â”‚â†“learningRateâ”‚
                                    â”‚ trainingâ”‚   â”‚or           â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚â†‘ l2Lambda   â”‚
                                                  â”‚â†‘ nBlocks    â”‚
                                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ˆ Use Case Examples

### ğŸŒ¡ï¸ Time Series Forecasting

```typescript
import { ConvolutionalRegression } from "jsr:@hviana/multivariate-convolutional-regression";

// Weather prediction from multiple sensors
const model = new ConvolutionalRegression({
  maxSequenceLength: 48, // 48 hours of history
  maxFutureSteps: 12, // Predict 12 hours ahead
  hiddenChannels: 32,
  nBlocks: 4,
});

// Features: [temperature, humidity, pressure, wind_speed]
// Targets: [temperature, humidity]
const historicalData = loadWeatherData();

// Train on streaming data
for (const observation of historicalData) {
  const result = model.fitOnline({
    xCoordinates: [observation.features],
    yCoordinates: [observation.targets],
  });

  if (result.driftDetected) {
    console.log("âš ï¸ Weather pattern shift detected!");
  }
}

// Forecast next 12 hours
const forecast = model.predict(12);
console.log(
  "ğŸŒ¡ï¸ Temperature forecast:",
  forecast.predictions.map((p) => p[0].toFixed(1)),
);
console.log("ğŸ“Š Confidence:", (forecast.confidence * 100).toFixed(0) + "%");
```

### ğŸ“Š Multi-Target Regression

```typescript
// Predict multiple outputs simultaneously
const model = new ConvolutionalRegression({
  maxSequenceLength: 32,
  hiddenChannels: 48,
  useDirectMultiHorizon: true, // Direct prediction for all targets
});

// Input: process parameters [temp, pressure, flow_rate, concentration]
// Output: quality metrics [yield, purity, efficiency]
const processData = loadProcessData();

for (const sample of processData) {
  model.fitOnline({
    xCoordinates: [sample.parameters],
    yCoordinates: [sample.quality],
  });
}

const prediction = model.predict();
console.log("ğŸ“¦ Predicted yield:", prediction.predictions[0][0].toFixed(2));
console.log("ğŸ’ Predicted purity:", prediction.predictions[0][1].toFixed(2));
console.log(
  "âš¡ Predicted efficiency:",
  prediction.predictions[0][2].toFixed(2),
);
```

### ğŸ“ˆ Financial Prediction with Uncertainty

```typescript
const model = new ConvolutionalRegression({
  maxSequenceLength: 60, // 60 trading days
  maxFutureSteps: 5, // 5-day forecast
  hiddenChannels: 64,
  nBlocks: 5,
  activation: "gelu",
  useLayerNorm: true,
  uncertaintyMultiplier: 1.96, // 95% confidence interval
  outlierThreshold: 2.5, // Handle market anomalies
});

// Features: [open, high, low, close, volume, volatility]
const marketData = loadMarketData();

for (const day of marketData) {
  model.fitOnline({
    xCoordinates: [day.features],
    yCoordinates: [[day.close]], // Predict closing price
  });
}

const forecast = model.predict(5);

console.log("\nğŸ“ˆ 5-Day Price Forecast:");
console.log("â”€".repeat(50));
for (let i = 0; i < 5; i++) {
  const pred = forecast.predictions[i][0];
  const lower = forecast.uncertaintyLower[i][0];
  const upper = forecast.uncertaintyUpper[i][0];
  console.log(
    `Day ${i + 1}: $${pred.toFixed(2)} [$${lower.toFixed(2)} - $${
      upper.toFixed(2)
    }]`,
  );
}
console.log(`\nğŸ¯ Confidence: ${(forecast.confidence * 100).toFixed(0)}%`);
```

### ğŸ”„ Online Learning with Drift Detection

```typescript
const model = new ConvolutionalRegression({
  maxSequenceLength: 32,
  adwinEnabled: true,
  adwinDelta: 0.001, // Sensitive drift detection
  learningRate: 0.002, // Slightly higher for adaptation
});

let totalSamples = 0;
let driftCount = 0;

// Simulate streaming data
const dataStream = createDataStream();

for await (const sample of dataStream) {
  const result = model.fitOnline({
    xCoordinates: [sample.features],
    yCoordinates: [sample.targets],
  });

  totalSamples++;

  if (result.driftDetected) {
    driftCount++;
    console.log(`\nğŸ”€ Drift #${driftCount} detected at sample ${totalSamples}`);
    console.log(`   Current loss: ${result.loss.toFixed(4)}`);
    console.log(`   Avg loss: ${result.metrics.avgLoss.toFixed(4)}`);
  }

  // Log progress every 1000 samples
  if (totalSamples % 1000 === 0) {
    console.log(
      `ğŸ“Š Samples: ${totalSamples}, MAE: ${result.metrics.mae.toFixed(4)}`,
    );
  }
}
```

### ğŸ’¾ Save and Load Model

```typescript
// Train model
const model = new ConvolutionalRegression({
  maxSequenceLength: 64,
  hiddenChannels: 32,
});

for (const sample of trainingData) {
  model.fitOnline({
    xCoordinates: [sample.x],
    yCoordinates: [sample.y],
  });
}

// Save model
const serialized = model.save();
await Deno.writeTextFile("model.json", serialized);
console.log("âœ… Model saved!");

// Load model later
const loaded = await Deno.readTextFile("model.json");
const restoredModel = new ConvolutionalRegression();
restoredModel.load(loaded);
console.log("âœ… Model loaded!");

// Continue training or predict
const prediction = restoredModel.predict();
```

### ğŸ“ Model Inspection

```typescript
const model = new ConvolutionalRegression({
  maxSequenceLength: 32,
  hiddenChannels: 16,
  nBlocks: 3,
});

// After training...
const summary = model.getModelSummary();

console.log("â•".repeat(60));
console.log("                    MODEL SUMMARY");
console.log("â•".repeat(60));
console.log(summary.architecture);
console.log("â”€".repeat(60));
console.log(`ğŸ“Š Total Parameters: ${summary.totalParams.toLocaleString()}`);
console.log(`ğŸ‘ï¸ Receptive Field: ${summary.receptiveField} timesteps`);
console.log(`ğŸ’¾ Memory Usage: ~${(summary.memoryBytes / 1024).toFixed(1)} KB`);
console.log(`ğŸ“ˆ Samples Trained: ${summary.sampleCount.toLocaleString()}`);
console.log("â•".repeat(60));

// Get normalization stats
const normStats = model.getNormalizationStats();
console.log("\nğŸ“ Normalization Statistics:");
console.log(`   Warmed up: ${normStats.isWarmedUp}`);
console.log(
  `   Input means: [${
    normStats.inputMeans.map((m) => m.toFixed(3)).join(", ")
  }]`,
);
console.log(
  `   Input stds: [${normStats.inputStds.map((s) => s.toFixed(3)).join(", ")}]`,
);
```

---

## ğŸ§® Mathematical Foundations

### Adam Optimizer

The Adam optimizer combines momentum with adaptive learning rates:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              ADAM UPDATE RULE                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   First moment estimate (momentum):                                         â”‚
â”‚   m_t = Î²â‚ Â· m_{t-1} + (1 - Î²â‚) Â· g_t                                      â”‚
â”‚                                                                             â”‚
â”‚   Second moment estimate (adaptive):                                        â”‚
â”‚   v_t = Î²â‚‚ Â· v_{t-1} + (1 - Î²â‚‚) Â· g_tÂ²                                     â”‚
â”‚                                                                             â”‚
â”‚   Bias-corrected estimates:                                                 â”‚
â”‚   mÌ‚_t = m_t / (1 - Î²â‚áµ—)                                                    â”‚
â”‚   vÌ‚_t = v_t / (1 - Î²â‚‚áµ—)                                                    â”‚
â”‚                                                                             â”‚
â”‚   Parameter update:                                                         â”‚
â”‚   Î¸_t = Î¸_{t-1} - Î± Â· mÌ‚_t / (âˆšvÌ‚_t + Îµ)                                    â”‚
â”‚                                                                             â”‚
â”‚   Where:                                                                    â”‚
â”‚   â€¢ g_t = gradient at time t                                                â”‚
â”‚   â€¢ Î± = learning rate (learningRate)                                        â”‚
â”‚   â€¢ Î²â‚ = first moment decay (beta1 = 0.9)                                  â”‚
â”‚   â€¢ Î²â‚‚ = second moment decay (beta2 = 0.999)                               â”‚
â”‚   â€¢ Îµ = numerical stability (epsilon = 1e-8)                                â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Welford Online Statistics

Numerically stable running mean and variance:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          WELFORD'S ALGORITHM                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   For each new value x_n:                                                   â”‚
â”‚                                                                             â”‚
â”‚   count = count + 1                                                         â”‚
â”‚   Î´ = x_n - mean                                                            â”‚
â”‚   mean = mean + Î´ / count                                                   â”‚
â”‚   Î´â‚‚ = x_n - mean                                                           â”‚
â”‚   Mâ‚‚ = Mâ‚‚ + Î´ Â· Î´â‚‚                                                          â”‚
â”‚                                                                             â”‚
â”‚   variance = Mâ‚‚ / (count - 1)    [sample variance]                          â”‚
â”‚   std = âˆš(max(variance, Îµ))                                                 â”‚
â”‚                                                                             â”‚
â”‚   Z-score normalization:                                                    â”‚
â”‚   z = (x - mean) / std                                                      â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ADWIN Drift Detection

Adaptive Windowing for distribution change detection:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       ADWIN DRIFT DETECTION                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   For window W = Wâ‚€ âˆª Wâ‚ (split into two subwindows):                      â”‚
â”‚                                                                             â”‚
â”‚   Hoeffding bound:                                                          â”‚
â”‚   Îµ = âˆš((1/(2m)) Â· ln(4/Î´))                                                â”‚
â”‚                                                                             â”‚
â”‚   Where m = 1/(1/nâ‚€ + 1/nâ‚) (harmonic mean of subwindow sizes)             â”‚
â”‚                                                                             â”‚
â”‚   Drift detected when:                                                      â”‚
â”‚   |Î¼â‚€ - Î¼â‚| > Îµ                                                             â”‚
â”‚                                                                             â”‚
â”‚   Where:                                                                    â”‚
â”‚   â€¢ Î¼â‚€, Î¼â‚ = means of subwindows Wâ‚€, Wâ‚                                    â”‚
â”‚   â€¢ Î´ = significance parameter (adwinDelta)                                 â”‚
â”‚   â€¢ nâ‚€, nâ‚ = sizes of subwindows                                           â”‚
â”‚                                                                             â”‚
â”‚   On drift: shrink window by removing oldest buckets                        â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### GELU Activation

Gaussian Error Linear Unit (smoother than ReLU):

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         GELU APPROXIMATION                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   GELU(x) â‰ˆ 0.5 Â· x Â· (1 + tanh(âˆš(2/Ï€) Â· (x + 0.044715 Â· xÂ³)))            â”‚
â”‚                                                                             â”‚
â”‚   Comparison with ReLU:                                                     â”‚
â”‚                                                                             â”‚
â”‚   ReLU(x) = max(0, x)        â”‚  GELU(x) = x Â· Î¦(x)                         â”‚
â”‚                               â”‚  where Î¦ is the Gaussian CDF               â”‚
â”‚        â”‚                      â”‚                                             â”‚
â”‚        â”‚    /                 â”‚       /~~                                   â”‚
â”‚        â”‚   /                  â”‚      /                                      â”‚
â”‚   â”€â”€â”€â”€â”€â”¼â”€â”€/â”€â”€â”€â”€â”€              â”‚  â”€â”€â”€/â”€â”€â”€â”€â”€â”€â”€â”€                               â”‚
â”‚        â”‚                      â”‚                                             â”‚
â”‚        â”‚                      â”‚                                             â”‚
â”‚                                                                             â”‚
â”‚   â€¢ GELU is smooth and differentiable everywhere                            â”‚
â”‚   â€¢ Better gradient flow for deep networks                                  â”‚
â”‚   â€¢ Slightly more expensive to compute                                      â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’¾ Serialization

### Save Model State

```typescript
const model = new ConvolutionalRegression({/* config */});

// Train model...

// Save to string
const serialized = model.save();

// Save to file
await Deno.writeTextFile("model.json", serialized);

// Or send over network
await fetch("/api/save-model", {
  method: "POST",
  body: serialized,
});
```

### Load Model State

```typescript
// Load from file
const json = await Deno.readTextFile("model.json");
const model = new ConvolutionalRegression();
model.load(json);

// Model is ready to use
const prediction = model.predict();
```

### What's Serialized

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         SERIALIZATION CONTENTS                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  âœ… Model Configuration (all parameters)                                    â”‚
â”‚  âœ… All Network Weights & Biases                                            â”‚
â”‚  âœ… Adam Optimizer State (m, v, timestep)                                   â”‚
â”‚  âœ… Welford Normalization Statistics                                        â”‚
â”‚  âœ… Input Ring Buffer (sequence history)                                    â”‚
â”‚  âœ… Residual Tracker (uncertainty data)                                     â”‚
â”‚  âœ… ADWIN Detector State (if enabled)                                       â”‚
â”‚  âœ… Sample Count                                                            â”‚
â”‚                                                                             â”‚
â”‚  âŒ Temporary Computation Buffers (recreated on load)                       â”‚
â”‚  âŒ Buffer Pool State (recreated on load)                                   â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit issues and pull requests
on [GitHub](https://github.com/hviana/multivariate-convolutional-regression).

---

## ğŸ“„ License

MIT License Â© 2025 [Henrique Emanoel Viana](https://github.com/hviana)

```
MIT License

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
```

---

<div align="center">

**Made with â¤ï¸ by [Henrique Emanoel Viana](https://github.com/hviana)**

â­ Star this repo if you find it useful!

</div>
