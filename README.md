Model: # ğŸ§  ConvolutionalRegression

<div align="center">

**High-Performance Convolutional Neural Network for Multivariate Regression with
Incremental Online Learning**

[Features](#-features) â€¢ [Quick Start](#-quick-start) â€¢
[Architecture](#-architecture) â€¢ [API Reference](#-api-reference) â€¢
[Parameters](#-configuration-parameters)

</div>

---

## ğŸ“‹ Table of Contents

- [âœ¨ Features](#-features)
- [ğŸš€ Quick Start](#-quick-start)
- [ğŸ—ï¸ Architecture](#ï¸-architecture)
- [ğŸ“– API Reference](#-api-reference)
- [âš™ï¸ Configuration Parameters](#ï¸-configuration-parameters)
- [ğŸ”§ Parameter Optimization Guide](#-parameter-optimization-guide)
- [ğŸ“Š Use Case Examples](#-use-case-examples)
- [ğŸ§® Mathematical Foundations](#-mathematical-foundations)
- [ğŸ¯ Best Practices](#-best-practices)
- [âš ï¸ Troubleshooting](#ï¸-troubleshooting)
- [ğŸ“ˆ Performance Tips](#-performance-tips)

---

## âœ¨ Features

<table>
<tr>
<td width="50%">

### ğŸ”· Core Neural Network

- **Conv1D Layers** with same padding
- **ReLU Activation** for non-linearity
- **Dense Output Layer** for regression
- **He Initialization** for optimal weight starting

</td>
<td width="50%">

### âš¡ Online Learning

- **Incremental Training** - learn sample by sample
- **Adam Optimizer** with momentum
- **Cosine Warmup** learning rate schedule
- **Adaptive Learning** without full retraining

</td>
</tr>
<tr>
<td width="50%">

### ğŸ“Š Normalization & Statistics

- **Welford's Algorithm** for running statistics
- **Z-Score Normalization** computed online
- **No Data Storage** required for normalization
- **Numerically Stable** computations

</td>
<td width="50%">

### ğŸ›¡ï¸ Robustness Features

- **L2 Regularization** prevents overfitting
- **Outlier Detection** & downweighting
- **ADWIN Drift Detection** for concept drift
- **Uncertainty Quantification** with confidence intervals

</td>
</tr>
</table>

---

## ğŸš€ Quick Start

### Basic Usage

```typescript
import { ConvolutionalRegression } from "jsr:@hviana/multivariate-convolutional-regression";

// 1ï¸âƒ£ Create model with default configuration
const model = new ConvolutionalRegression();

// 2ï¸âƒ£ Prepare training data
const trainingData = {
  xCoordinates: [
    [1.0, 2.0, 3.0],
    [2.0, 3.0, 4.0],
    [3.0, 4.0, 5.0],
    [4.0, 5.0, 6.0],
  ],
  yCoordinates: [
    [4.0],
    [5.0],
    [6.0],
    [7.0],
  ],
};

// 3ï¸âƒ£ Train incrementally
const result = model.fitOnline(trainingData);
console.log(`ğŸ“‰ Loss: ${result.loss.toFixed(6)}`);
console.log(`ğŸ“ˆ Learning Rate: ${result.effectiveLearningRate.toFixed(6)}`);

// 4ï¸âƒ£ Generate predictions
const predictions = model.predict(5);
predictions.predictions.forEach((pred, i) => {
  console.log(
    `Step ${i + 1}: ${pred.predicted[0].toFixed(4)} Â± ${
      pred.standardError[0].toFixed(4)
    }`,
  );
});
```

### Output Example

```
ğŸ“‰ Loss: 0.023451
ğŸ“ˆ Learning Rate: 0.000040
Step 1: 7.9823 Â± 0.1234
Step 2: 8.9756 Â± 0.1567
Step 3: 9.9634 Â± 0.1823
Step 4: 10.9512 Â± 0.2134
Step 5: 11.9389 Â± 0.2456
```

---

## ğŸ—ï¸ Architecture

### Network Structure

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CONVOLUTIONAL REGRESSION NETWORK                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚   â”‚   INPUT     â”‚    â”‚     HIDDEN CONVOLUTIONAL LAYERS     â”‚    â”‚ OUTPUT â”‚ â”‚
â”‚   â”‚   LAYER     â”‚    â”‚                                     â”‚    â”‚ LAYER  â”‚ â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚   â”‚           â”‚      â”‚ Conv1D  â”‚      â”‚ Conv1D  â”‚              â”‚  Dense  â”‚ â”‚
â”‚   â”‚  Input    â”‚â”€â”€â”€â”€â”€â–¶â”‚    +    â”‚â”€â”€â”€â”€â”€â–¶â”‚    +    â”‚â”€â”€â”€â”€â”€â–¶ ... â”€â”€â–¶â”‚  Layer  â”‚ â”‚
â”‚   â”‚ (inputDim)â”‚      â”‚  ReLU   â”‚      â”‚  ReLU   â”‚              â”‚         â”‚ â”‚
â”‚   â”‚           â”‚      â”‚         â”‚      â”‚         â”‚              â”‚         â”‚ â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚        â”‚                  â”‚                â”‚                        â”‚       â”‚
â”‚        â–¼                  â–¼                â–¼                        â–¼       â”‚
â”‚   [1 Ã— spatial]    [filters Ã— spatial]  [filters Ã— spatial]   [outputDim]  â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Architecture Formula:
Input(inputDim) â†’ [Conv1D(filters, kernelSize, same) â†’ ReLU]Ã—L â†’ Flatten â†’ Dense(outputDim)
```

### Data Flow Diagram

```
                        TRAINING PIPELINE
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Raw    â”‚   â”‚  Welford   â”‚   â”‚  Z-Score â”‚   â”‚  Normalized  â”‚ â”‚
â”‚  â”‚   Data   â”‚â”€â”€â–¶â”‚  Update    â”‚â”€â”€â–¶â”‚  Norm    â”‚â”€â”€â–¶â”‚    Data      â”‚ â”‚
â”‚  â”‚ (x, y)   â”‚   â”‚ (Î¼, ÏƒÂ²)    â”‚   â”‚          â”‚   â”‚   (xÌƒ, á»¹)     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                        â”‚         â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                    â–¼                                             â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚           â”‚  Forward Pass   â”‚                                    â”‚
â”‚           â”‚  Convâ†’ReLUâ†’Denseâ”‚                                    â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚                    â”‚                                             â”‚
â”‚                    â–¼                                             â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚           â”‚  Compute Loss   â”‚â”€â”€â–¶â”‚   Outlier   â”‚                 â”‚
â”‚           â”‚  MSE + L2 Reg   â”‚   â”‚  Detection  â”‚                 â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                    â”‚                                             â”‚
â”‚                    â–¼                                             â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚           â”‚  Backward Pass  â”‚â”€â”€â–¶â”‚    ADWIN    â”‚                 â”‚
â”‚           â”‚  Compute âˆ‡L     â”‚   â”‚  Drift Det  â”‚                 â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                    â”‚                                             â”‚
â”‚                    â–¼                                             â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚           â”‚   Adam Update   â”‚                                    â”‚
â”‚           â”‚  with Warmup    â”‚                                    â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“– API Reference

### Constructor

```typescript
const model = new ConvolutionalRegression(config?: ConvolutionalRegressionConfig);
```

### Main Methods

| Method                    | Description                  | Returns              |
| ------------------------- | ---------------------------- | -------------------- |
| `fitOnline(data)`         | Incremental online training  | `FitResult`          |
| `predict(steps)`          | Generate future predictions  | `PredictionResult`   |
| `getModelSummary()`       | Get model state summary      | `ModelSummary`       |
| `getWeights()`            | Export model weights         | `WeightInfo`         |
| `getNormalizationStats()` | Get normalization statistics | `NormalizationStats` |
| `reset()`                 | Reset model to initial state | `void`               |

### Interfaces

<details>
<summary><b>ğŸ“¥ FitInput</b> - Training data structure</summary>

```typescript
interface FitInput {
  /** Input features: [numSamples][inputDim] */
  xCoordinates: number[][];
  /** Target outputs: [numSamples][outputDim] */
  yCoordinates: number[][];
}
```

**Example:**

```typescript
const data: FitInput = {
  xCoordinates: [[1, 2, 3], [4, 5, 6], [7, 8, 9]],
  yCoordinates: [[10, 11], [12, 13], [14, 15]],
};
```

</details>

<details>
<summary><b>ğŸ“¤ FitResult</b> - Training step result</summary>

```typescript
interface FitResult {
  loss: number; // Current MSE loss value
  gradientNorm: number; // L2 norm of gradient vector
  effectiveLearningRate: number; // LR after warmup/decay
  isOutlier: boolean; // Sample flagged as outlier
  converged: boolean; // Model has converged
  sampleIndex: number; // Index of processed sample
  driftDetected: boolean; // Concept drift detected
}
```

</details>

<details>
<summary><b>ğŸ”® PredictionResult</b> - Prediction output</summary>

```typescript
interface PredictionResult {
  predictions: SinglePrediction[]; // Predictions for each step
  accuracy: number; // Model accuracy: 1/(1 + avgLoss)
  sampleCount: number; // Total samples processed
  isModelReady: boolean; // Model ready for prediction
}

interface SinglePrediction {
  predicted: number[]; // Point estimate
  lowerBound: number[]; // Lower 95% CI
  upperBound: number[]; // Upper 95% CI
  standardError: number[]; // Standard error per dimension
}
```

</details>

<details>
<summary><b>ğŸ“Š ModelSummary</b> - Model state overview</summary>

```typescript
interface ModelSummary {
  isInitialized: boolean; // Network initialized
  inputDimension: number; // Auto-detected input dim
  outputDimension: number; // Auto-detected output dim
  hiddenLayers: number; // Number of conv layers
  convolutionsPerLayer: number; // Filters per layer
  kernelSize: number; // Convolution kernel size
  totalParameters: number; // Total trainable params
  sampleCount: number; // Samples processed
  accuracy: number; // Current accuracy metric
  converged: boolean; // Training converged
  effectiveLearningRate: number; // Current learning rate
  driftCount: number; // Detected drift events
}
```

</details>

---

## âš™ï¸ Configuration Parameters

### Complete Parameter Reference

```typescript
interface ConvolutionalRegressionConfig {
  // Network Architecture
  hiddenLayers?: number; // 1-10, default: 2
  convolutionsPerLayer?: number; // 1-256, default: 32
  kernelSize?: number; // â‰¥1, default: 3

  // Adam Optimizer
  learningRate?: number; // >0, default: 0.001
  warmupSteps?: number; // â‰¥0, default: 100
  totalSteps?: number; // â‰¥1, default: 10000
  beta1?: number; // 0-0.9999, default: 0.9
  beta2?: number; // 0-0.9999, default: 0.999
  epsilon?: number; // >0, default: 1e-8

  // Regularization
  regularizationStrength?: number; // â‰¥0, default: 1e-4
  convergenceThreshold?: number; // â‰¥0, default: 1e-6

  // Robustness
  outlierThreshold?: number; // â‰¥0, default: 3.0
  adwinDelta?: number; // 0-1, default: 0.002
}
```

### Parameter Visual Guide

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PARAMETER CATEGORIES                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  ğŸ—ï¸ ARCHITECTURE          âš¡ OPTIMIZER           ğŸ›¡ï¸ ROBUSTNESS             â”‚
â”‚  â”œâ”€ hiddenLayers          â”œâ”€ learningRate       â”œâ”€ regularizationStrength â”‚
â”‚  â”œâ”€ convolutionsPerLayer  â”œâ”€ warmupSteps        â”œâ”€ convergenceThreshold   â”‚
â”‚  â””â”€ kernelSize            â”œâ”€ totalSteps         â”œâ”€ outlierThreshold       â”‚
â”‚                           â”œâ”€ beta1              â””â”€ adwinDelta             â”‚
â”‚                           â”œâ”€ beta2                                         â”‚
â”‚                           â””â”€ epsilon                                       â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Parameter Optimization Guide

### ğŸ—ï¸ Architecture Parameters

#### `hiddenLayers` - Network Depth

Controls the number of convolutional layers in the network.

```
Complexity vs Depth Trade-off:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Layers â”‚ Capacity   â”‚ Training Speed â”‚ Best For
â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  1    â”‚ â–“â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     â”‚ Simple linear relationships
  2    â”‚ â–“â–“â–“â–‘â–‘â–‘â–‘â–‘â–‘â–‘ â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘     â”‚ Most general use cases âœ“
  3-4  â”‚ â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘ â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘     â”‚ Complex patterns
  5-7  â”‚ â–“â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘ â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘     â”‚ Highly non-linear data
  8-10 â”‚ â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“ â”‚ â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘     â”‚ Very complex sequences
```

<details>
<summary><b>ğŸ“Œ Optimization Examples</b></summary>

**Simple Time Series (e.g., daily temperature):**

```typescript
const model = new ConvolutionalRegression({
  hiddenLayers: 1, // Simple pattern
  convolutionsPerLayer: 16,
});
```

**Financial Data (e.g., stock prices):**

```typescript
const model = new ConvolutionalRegression({
  hiddenLayers: 3, // Medium complexity
  convolutionsPerLayer: 64,
});
```

**Complex Multivariate Signals (e.g., sensor fusion):**

```typescript
const model = new ConvolutionalRegression({
  hiddenLayers: 5, // High complexity
  convolutionsPerLayer: 128,
});
```

</details>

---

#### `convolutionsPerLayer` - Network Width

Determines the number of filters (feature detectors) per convolutional layer.

```
Feature Extraction Capacity:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Filters â”‚ Parameters â”‚ Memory Usage â”‚ Feature Diversity
â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  8-16  â”‚ Low        â”‚ ~100KB       â”‚ Basic patterns
  32    â”‚ Medium     â”‚ ~500KB       â”‚ Standard use âœ“
  64    â”‚ High       â”‚ ~2MB         â”‚ Rich features
  128   â”‚ Very High  â”‚ ~8MB         â”‚ Complex features
  256   â”‚ Maximum    â”‚ ~32MB        â”‚ Full capacity
```

**Rule of Thumb:**

```
filters â‰ˆ âˆš(input_dimension Ã— output_dimension) Ã— complexity_factor

where complexity_factor:
  - Simple data: 1-2
  - Medium complexity: 2-4
  - Complex data: 4-8
```

<details>
<summary><b>ğŸ“Œ Code Examples</b></summary>

```typescript
// Low memory environment (embedded systems)
const lightModel = new ConvolutionalRegression({
  convolutionsPerLayer: 8,
  hiddenLayers: 1,
});

// Standard application
const standardModel = new ConvolutionalRegression({
  convolutionsPerLayer: 32, // Default
  hiddenLayers: 2,
});

// High-accuracy requirement
const accurateModel = new ConvolutionalRegression({
  convolutionsPerLayer: 128,
  hiddenLayers: 4,
});
```

</details>

---

#### `kernelSize` - Temporal Receptive Field

Controls how many adjacent input positions each filter examines.

```
Receptive Field Visualization:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Input:    [xâ‚] [xâ‚‚] [xâ‚ƒ] [xâ‚„] [xâ‚…] [xâ‚†] [xâ‚‡] [xâ‚ˆ]

kernel=3:  â””â”€â”¬â”€â”€â”˜          Captures local patterns
             â””â”€â”€â”˜          (3 adjacent values)

kernel=5:  â””â”€â”€â”€â”¬â”€â”€â”€â”˜       Captures medium-range patterns
               â””â”€â”€â”€â”˜       (5 adjacent values)

kernel=7:  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   Captures long-range patterns
                 â””â”€â”€â”€â”€â”€â”˜   (7 adjacent values)
```

| Kernel Size | Pattern Type               | Use Case Example         |
| ----------- | -------------------------- | ------------------------ |
| `1`         | Point-wise transformations | Feature scaling          |
| `3`         | Short-term dependencies    | High-frequency signals âœ“ |
| `5`         | Medium-term patterns       | Daily/weekly patterns    |
| `7`         | Long-term dependencies     | Seasonal trends          |
| `9+`        | Very long patterns         | Monthly/yearly cycles    |

<details>
<summary><b>ğŸ“Œ Selection Guide</b></summary>

```typescript
// High-frequency signal (millisecond samples)
const highFreqModel = new ConvolutionalRegression({
  kernelSize: 3, // Capture fast changes
  hiddenLayers: 2,
});

// Daily data with weekly patterns
const weeklyModel = new ConvolutionalRegression({
  kernelSize: 7, // Week = 7 days
  hiddenLayers: 3,
});

// Hourly data with daily patterns
const dailyModel = new ConvolutionalRegression({
  kernelSize: 5, // Capture ~5 hour windows
  hiddenLayers: 2,
});
```

**Pro Tip:** Use odd kernel sizes (3, 5, 7) for symmetric padding.

</details>

---

### âš¡ Optimizer Parameters

#### `learningRate` - Step Size

The most critical hyperparameter controlling update magnitude.

```
Learning Rate Spectrum:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

       1e-5        1e-4        1e-3        1e-2        1e-1
        â”‚           â”‚           â”‚           â”‚           â”‚
        â–¼           â–¼           â–¼           â–¼           â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Very   â”‚  Fine     â”‚  Default  â”‚  Fast     â”‚ Unstableâ”‚
   â”‚  Slow   â”‚  Tuning   â”‚  âœ“        â”‚           â”‚         â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   
   Convergence:  Slow â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Fast
   Stability:    High â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Low
```

**Learning Rate Selection Decision Tree:**

```
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ Is training stable? â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â–¼                â–¼                â–¼
  No/Diverging    Oscillating      Converging
     â”‚                â”‚                â”‚
     â–¼                â–¼                â–¼
Reduce by 10x    Reduce by 2-5x   Check speed
     â”‚                â”‚                â”‚
     â–¼                â–¼                â–¼
 lr Ã— 0.1         lr Ã— 0.3         Too slow?
                                       â”‚
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â–¼                       â–¼
                          Yes                      No
                           â”‚                       â”‚
                           â–¼                       â–¼
                     Increase by 2x            Keep lr âœ“
```

<details>
<summary><b>ğŸ“Œ Practical Examples</b></summary>

```typescript
// Conservative approach (noisy data)
const conservativeModel = new ConvolutionalRegression({
  learningRate: 0.0001, // 10x smaller
  warmupSteps: 200, // Longer warmup
});

// Standard approach
const standardModel = new ConvolutionalRegression({
  learningRate: 0.001, // Default
  warmupSteps: 100,
});

// Aggressive approach (clean data, fast training)
const aggressiveModel = new ConvolutionalRegression({
  learningRate: 0.005, // 5x larger
  warmupSteps: 50, // Shorter warmup
});
```

**Adaptive Strategy:**

```typescript
// Start conservative, increase if stable
function adaptiveLearningRate(lossHistory: number[]): number {
  const recentLosses = lossHistory.slice(-10);
  const isStable = recentLosses.every((l, i) =>
    i === 0 || l <= recentLosses[i - 1] * 1.1
  );

  return isStable ? 0.002 : 0.0005;
}
```

</details>

---

#### `warmupSteps` & `totalSteps` - Learning Rate Schedule

Controls the learning rate progression over training.

```
Learning Rate Schedule Visualization:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

LR â”‚
   â”‚     â•­â”€â”€â”€â”€â”€â”€â”€â”€â•®
   â”‚    â•±          â•²
   â”‚   â•±            â•²
   â”‚  â•±              â•²
   â”‚ â•±                â•²
   â”‚â•±                  â•²_____________
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Steps
   â”‚â—€â”€â”€â”€â”€â”€â–¶â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚
    Warmup      Cosine Decay Phase

Formula:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Warmup (t â‰¤ warmupSteps):                                   â”‚
â”‚   lr(t) = learningRate Ã— (t / warmupSteps)                  â”‚
â”‚                                                             â”‚
â”‚ Decay (t > warmupSteps):                                    â”‚
â”‚   progress = (t - warmupSteps) / (totalSteps - warmupSteps) â”‚
â”‚   lr(t) = learningRate Ã— 0.5 Ã— (1 + cos(Ï€ Ã— progress))      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

<details>
<summary><b>ğŸ“Œ Schedule Configurations</b></summary>

```typescript
// Quick training (small dataset, <1000 samples)
const quickConfig = {
  warmupSteps: 50,
  totalSteps: 2000,
  learningRate: 0.002,
};

// Standard training (medium dataset, 1000-10000 samples)
const standardConfig = {
  warmupSteps: 100,
  totalSteps: 10000,
  learningRate: 0.001,
};

// Long training (large dataset, >10000 samples)
const longConfig = {
  warmupSteps: 500,
  totalSteps: 50000,
  learningRate: 0.0005,
};

// Streaming/continuous training
const streamingConfig = {
  warmupSteps: 100,
  totalSteps: 1000000, // Very long decay
  learningRate: 0.001,
};
```

</details>

---

#### `beta1` & `beta2` - Adam Momentum Parameters

Control the exponential moving averages in Adam optimizer.

```
Adam Update Visualization:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚          ADAM OPTIMIZER                â”‚
             â”‚                                        â”‚
  gradient   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
      g  â”€â”€â”€â–¶â”‚  â”‚ m = Î²â‚Â·m + (1-Î²â‚)Â·g             â”‚  â”‚  First moment
             â”‚  â”‚     (Momentum / Direction)       â”‚  â”‚  (Î²â‚ = 0.9)
             â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
             â”‚                 â”‚                     â”‚
             â”‚                 â–¼                     â”‚
             â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
      gÂ² â”€â”€â”€â–¶â”‚  â”‚ v = Î²â‚‚Â·v + (1-Î²â‚‚)Â·gÂ²            â”‚  â”‚  Second moment
             â”‚  â”‚     (Adaptive learning rate)     â”‚  â”‚  (Î²â‚‚ = 0.999)
             â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
             â”‚                 â”‚                     â”‚
             â”‚                 â–¼                     â”‚
             â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
             â”‚  â”‚        mÌ‚                         â”‚  â”‚
             â”‚  â”‚ Î”w = â”€â”€â”€â”€â”€â”€â”€â”€â”€                   â”‚  â”‚  Weight update
             â”‚  â”‚      âˆšvÌ‚ + Îµ                      â”‚  â”‚
             â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| Parameter | Default | Range        | Effect                                     |
| --------- | ------- | ------------ | ------------------------------------------ |
| `beta1`   | 0.9     | 0.8-0.99     | Higher = smoother gradients, more momentum |
| `beta2`   | 0.999   | 0.99-0.9999  | Higher = more stable per-parameter LR      |
| `epsilon` | 1e-8    | 1e-10 - 1e-6 | Prevents division by zero                  |

<details>
<summary><b>ğŸ“Œ When to Adjust</b></summary>

```typescript
// Noisy gradients (reduce momentum)
const noisyConfig = {
  beta1: 0.85, // Less momentum
  beta2: 0.999, // Keep stable
  learningRate: 0.0005,
};

// Sparse gradients (increase momentum)
const sparseConfig = {
  beta1: 0.95, // More momentum
  beta2: 0.9999, // Very stable scaling
  learningRate: 0.001,
};

// Default (works for most cases)
const defaultConfig = {
  beta1: 0.9,
  beta2: 0.999,
  epsilon: 1e-8,
};
```

</details>

---

### ğŸ›¡ï¸ Robustness Parameters

#### `regularizationStrength` - L2 Penalty

Prevents overfitting by penalizing large weights.

```
L2 Regularization Effect:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Loss Function:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                     â”‚
â”‚   L_total = L_MSE + (Î»/2) Ã— Î£ wÂ²                   â”‚
â”‚             â”€â”€â”€â”€â”€   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                  â”‚
â”‚              â–²           â–²                          â”‚
â”‚              â”‚           â”‚                          â”‚
â”‚         Data fit    Weight penalty                  â”‚
â”‚                    (regularization)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Effect on Weights:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Î» = 0 (no reg)     â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚  Large weights allowed
Î» = 1e-5           â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â”‚  Slight constraint
Î» = 1e-4 (default) â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚  Balanced âœ“
Î» = 1e-3           â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚  Strong constraint
Î» = 1e-2           â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚  Very strong
```

<details>
<summary><b>ğŸ“Œ Selection Guide</b></summary>

```typescript
// Large dataset, low risk of overfitting
const largeDatsetConfig = {
  regularizationStrength: 1e-5, // Minimal regularization
};

// Standard dataset
const standardConfig = {
  regularizationStrength: 1e-4, // Default
};

// Small dataset, high overfitting risk
const smallDatasetConfig = {
  regularizationStrength: 1e-3, // Strong regularization
};

// Very small dataset (<100 samples)
const tinyDatasetConfig = {
  regularizationStrength: 5e-3, // Very strong
  hiddenLayers: 1, // Simpler model
  convolutionsPerLayer: 16,
};
```

**Validation Strategy:**

```typescript
function selectRegularization(trainLoss: number, valLoss: number): number {
  const overfitRatio = valLoss / trainLoss;

  if (overfitRatio > 2.0) return 1e-3; // High overfitting
  if (overfitRatio > 1.5) return 5e-4; // Moderate overfitting
  if (overfitRatio > 1.2) return 1e-4; // Slight overfitting
  return 1e-5; // Minimal overfitting
}
```

</details>

---

#### `outlierThreshold` - Anomaly Sensitivity

Z-score threshold for detecting and downweighting outliers.

```
Outlier Detection Mechanism:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

                    Normal Distribution of Errors
                           
                              â–²
                             â•±â”‚â•²
                            â•± â”‚ â•²
                           â•±  â”‚  â•²
                          â•±   â”‚   â•²
                         â•±    â”‚    â•²
                        â•±     â”‚     â•²
                    â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â”‚â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬
               â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â–¶
                  -3Ïƒ   -2Ïƒ   Î¼   +2Ïƒ   +3Ïƒ
                   â”‚                     â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
               outlierThreshold = 3.0 (default)
               
                   Points beyond Â±3Ïƒ are outliers
                   and receive 0.1Ã— weight
```

| Threshold | Coverage | False Positive Rate | Use Case                   |
| --------- | -------- | ------------------- | -------------------------- |
| `2.0`     | 95.4%    | High (4.6%)         | Aggressive outlier removal |
| `2.5`     | 98.8%    | Medium (1.2%)       | Moderate sensitivity       |
| `3.0`     | 99.7%    | Low (0.3%)          | Standard (default) âœ“       |
| `3.5`     | 99.95%   | Very Low            | Conservative               |
| `4.0`     | 99.99%   | Minimal             | Only extreme outliers      |

<details>
<summary><b>ğŸ“Œ Configuration Examples</b></summary>

```typescript
// Clean data (minimal outliers expected)
const cleanDataConfig = {
  outlierThreshold: 4.0, // Only extreme cases
};

// Sensor data (occasional spikes)
const sensorConfig = {
  outlierThreshold: 3.0, // Default works well
};

// Financial data (frequent outliers)
const financialConfig = {
  outlierThreshold: 2.5, // More aggressive detection
};

// Noisy IoT data
const iotConfig = {
  outlierThreshold: 2.0, // Very aggressive
  regularizationStrength: 1e-3, // Also increase regularization
};
```

</details>

---

#### `adwinDelta` - Drift Detection Sensitivity

Controls the ADWIN algorithm's sensitivity to concept drift.

```
ADWIN Concept Drift Detection:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

                    Sliding Window
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚     Wâ‚€ (old data)    â”‚   Wâ‚ (new data)   â”‚
    â”‚    Î¼â‚€ = 0.05         â”‚   Î¼â‚ = 0.15       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                     cut point

    Drift detected if: |Î¼â‚€ - Î¼â‚| â‰¥ Îµ_cut
    
    where: Îµ_cut = âˆš((1/2m) Ã— ln(4|W|/Î´))
    
    Î´ = adwinDelta (smaller = more sensitive)
```

```
Sensitivity Spectrum:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

  Î´ = 0.1      Î´ = 0.01     Î´ = 0.002    Î´ = 0.0001
     â”‚            â”‚             â”‚             â”‚
     â–¼            â–¼             â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Low    â”‚  Medium   â”‚   Default   â”‚    High     â”‚
â”‚Sensitiv.â”‚Sensitivityâ”‚     âœ“       â”‚ Sensitivity â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

False Alarms:  Few â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Many
Drift Detect:  Slow â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Fast
```

<details>
<summary><b>ğŸ“Œ Application-Specific Settings</b></summary>

```typescript
// Stable environment (rare drift)
const stableConfig = {
  adwinDelta: 0.01, // Low sensitivity
};

// Dynamic environment (frequent changes)
const dynamicConfig = {
  adwinDelta: 0.001, // High sensitivity
};

// Critical applications (immediate drift response)
const criticalConfig = {
  adwinDelta: 0.0001, // Very high sensitivity
  learningRate: 0.002, // Fast adaptation
};

// Monitoring drift without over-reacting
const monitoringConfig = {
  adwinDelta: 0.002, // Default, balanced
};
```

**Handling Drift Events:**

```typescript
const model = new ConvolutionalRegression({ adwinDelta: 0.002 });

function trainWithDriftHandling(data: FitInput) {
  const result = model.fitOnline(data);

  if (result.driftDetected) {
    console.log("âš ï¸ Concept drift detected!");
    // Option 1: Log and continue
    // Option 2: Increase learning rate temporarily
    // Option 3: Reset model for major drift
  }

  return result;
}
```

</details>

---

## ğŸ“Š Use Case Examples

### ğŸ“ˆ Time Series Forecasting

```typescript
/**
 * Stock Price Prediction Example
 * Features: [open, high, low, close, volume]
 * Target: [next_close]
 */
const stockModel = new ConvolutionalRegression({
  hiddenLayers: 3,
  convolutionsPerLayer: 64,
  kernelSize: 5, // Weekly patterns (5 trading days)
  learningRate: 0.0005, // Conservative for noisy data
  regularizationStrength: 1e-3,
  outlierThreshold: 2.5, // Financial data has outliers
});

// Training
for (const batch of stockDataBatches) {
  const result = stockModel.fitOnline({
    xCoordinates: batch.features,
    yCoordinates: batch.targets,
  });

  if (result.driftDetected) {
    console.log("ğŸ“Š Market regime change detected");
  }
}

// Prediction with confidence intervals
const forecast = stockModel.predict(5); // 5-day forecast
forecast.predictions.forEach((pred, day) => {
  console.log(
    `Day ${day + 1}: $${pred.predicted[0].toFixed(2)} ` +
      `(95% CI: $${pred.lowerBound[0].toFixed(2)} - ` +
      `$${pred.upperBound[0].toFixed(2)})`,
  );
});
```

---

### ğŸŒ¡ï¸ Sensor Data Regression

```typescript
/**
 * Temperature Prediction from Multiple Sensors
 * Input: [sensor1, sensor2, sensor3, humidity, pressure]
 * Output: [temperature]
 */
const sensorModel = new ConvolutionalRegression({
  hiddenLayers: 2,
  convolutionsPerLayer: 32,
  kernelSize: 3,
  learningRate: 0.001,
  warmupSteps: 50,
  outlierThreshold: 3.0, // Handle sensor noise
});

// Continuous online learning
function processSensorReading(reading: SensorReading) {
  const result = sensorModel.fitOnline({
    xCoordinates: [reading.features],
    yCoordinates: [reading.temperature],
  });

  if (result.isOutlier) {
    console.warn("âš ï¸ Outlier detected - possible sensor malfunction");
  }

  return {
    loss: result.loss,
    prediction: sensorModel.predict(1).predictions[0],
  };
}
```

---

### ğŸ¤– Real-time Control Systems

```typescript
/**
 * Robot Joint Position Prediction
 * Input: [joint_angles Ã— 6, velocities Ã— 6]
 * Output: [target_position Ã— 3]
 */
const controlModel = new ConvolutionalRegression({
  hiddenLayers: 2,
  convolutionsPerLayer: 48,
  kernelSize: 3,
  learningRate: 0.002, // Fast adaptation
  warmupSteps: 20, // Quick warmup
  totalSteps: 5000,
  adwinDelta: 0.001, // Detect environmental changes
  convergenceThreshold: 1e-5,
});

// Real-time loop
async function controlLoop() {
  while (running) {
    const state = await getRobotState();

    // Update model with latest data
    const result = controlModel.fitOnline({
      xCoordinates: [state.input],
      yCoordinates: [state.targetPosition],
    });

    // Get next position prediction
    const prediction = controlModel.predict(1);

    if (prediction.isModelReady) {
      await sendCommand(prediction.predictions[0].predicted);
    }

    await sleep(10); // 100Hz control loop
  }
}
```

---

### ğŸ“Š Multi-Output Regression

```typescript
/**
 * Energy Consumption Forecasting
 * Input: [hour, dayOfWeek, month, temperature, humidity]
 * Output: [electricity, gas, water]
 */
const energyModel = new ConvolutionalRegression({
  hiddenLayers: 3,
  convolutionsPerLayer: 64,
  kernelSize: 7, // Weekly patterns
  learningRate: 0.001,
  regularizationStrength: 1e-4,
});

// Batch training
const history = [];
for (let epoch = 0; epoch < 10; epoch++) {
  const result = energyModel.fitOnline({
    xCoordinates: trainingFeatures,
    yCoordinates: trainingTargets,
  });

  history.push({
    epoch,
    loss: result.loss,
    accuracy: energyModel.getModelSummary().accuracy,
  });
}

// Multi-step forecast
const forecast = energyModel.predict(24); // 24-hour forecast
console.log("\nğŸ“Š 24-Hour Energy Forecast:");
console.log("Hour | Electricity | Gas    | Water");
console.log("-----|-------------|--------|-------");
forecast.predictions.forEach((pred, hour) => {
  console.log(
    `${(hour + 1).toString().padStart(4)} | ` +
      `${pred.predicted[0].toFixed(2).padStart(11)} | ` +
      `${pred.predicted[1].toFixed(2).padStart(6)} | ` +
      `${pred.predicted[2].toFixed(2).padStart(5)}`,
  );
});
```

---

## ğŸ§® Mathematical Foundations

### Convolution Operation (Conv1D)

```
Same Padding Convolution:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Input x:   [xâ‚€, xâ‚, xâ‚‚, xâ‚ƒ, xâ‚„]    (spatial = 5)
Kernel w:  [wâ‚€, wâ‚, wâ‚‚]            (kernelSize = 3)
Padding:   pad = (kernelSize - 1) / 2 = 1

Output y[i] = Î£â±¼ w[j] Ã— x[i + j - pad]  (with zero-padding)

Example (i=0):
  y[0] = w[0]Ã—0 + w[1]Ã—x[0] + w[2]Ã—x[1]
         (pad)

Example (i=2):
  y[2] = w[0]Ã—x[1] + w[1]Ã—x[2] + w[2]Ã—x[3]
```

### Welford's Online Algorithm

```
Numerically Stable Running Statistics:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

For each new sample xâ‚™:

  1. Î´ = xâ‚™ - Î¼â‚™â‚‹â‚           // Difference from current mean
  2. Î¼â‚™ = Î¼â‚™â‚‹â‚ + Î´/n         // Update mean
  3. Î´â‚‚ = xâ‚™ - Î¼â‚™            // New difference
  4. Mâ‚‚â‚™ = Mâ‚‚â‚™â‚‹â‚ + Î´ Ã— Î´â‚‚    // Update sum of squared deviations

Final variance: ÏƒÂ² = Mâ‚‚/(n-1)   // Bessel's correction
```

### Adam Optimizer

```
Adam Update Rule:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

At timestep t:

  1. m_t = Î²â‚ Ã— m_{t-1} + (1 - Î²â‚) Ã— g_t     // First moment
  2. v_t = Î²â‚‚ Ã— v_{t-1} + (1 - Î²â‚‚) Ã— g_tÂ²    // Second moment
  
  3. mÌ‚_t = m_t / (1 - Î²â‚áµ—)                   // Bias correction
  4. vÌ‚_t = v_t / (1 - Î²â‚‚áµ—)                   // Bias correction
  
  5. Î¸_t = Î¸_{t-1} - Î± Ã— mÌ‚_t / (âˆšvÌ‚_t + Îµ)   // Update weights

With L2 regularization:
  g_t = âˆ‡L(Î¸) + Î» Ã— Î¸                        // Add weight decay
```

### ADWIN Drift Detection

```
Adaptive Windowing Algorithm:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Window W with subwindows Wâ‚€, Wâ‚:

  Î¼â‚€ = mean(Wâ‚€), Î¼â‚ = mean(Wâ‚)
  m = harmonic_mean(|Wâ‚€|, |Wâ‚|)
  
  Îµ_cut = âˆš((1/2m) Ã— ln(4|W|/Î´))
  
  Drift detected if: |Î¼â‚€ - Î¼â‚| â‰¥ Îµ_cut
  
  On detection: discard Wâ‚€, continue with Wâ‚
```

---

## ğŸ¯ Best Practices

### âœ… Do's

```typescript
// âœ… Start with defaults, then tune
const model = new ConvolutionalRegression(); // Defaults are well-tuned

// âœ… Monitor training progress
const result = model.fitOnline(data);
if (result.loss > previousLoss * 2) {
  console.warn("Loss spike detected");
}

// âœ… Use model summary for debugging
const summary = model.getModelSummary();
console.log(`Accuracy: ${(summary.accuracy * 100).toFixed(2)}%`);

// âœ… Handle drift events
if (result.driftDetected) {
  // Log, adjust, or reset as needed
}

// âœ… Validate predictions
const pred = model.predict(1);
if (!pred.isModelReady) {
  console.warn("Model needs more training data");
}
```

### âŒ Don'ts

```typescript
// âŒ Don't use extreme learning rates
const bad1 = new ConvolutionalRegression({ learningRate: 1.0 }); // Too high!

// âŒ Don't skip warmup for new models
const bad2 = new ConvolutionalRegression({ warmupSteps: 0 }); // Unstable start

// âŒ Don't use too many layers for simple data
const bad3 = new ConvolutionalRegression({ hiddenLayers: 10 }); // Overkill

// âŒ Don't ignore outlier flags
const result = model.fitOnline(data);
// Always check: result.isOutlier

// âŒ Don't predict without sufficient training
const newModel = new ConvolutionalRegression();
newModel.predict(10); // isModelReady will be false!
```

---

## âš ï¸ Troubleshooting

### Common Issues & Solutions

<details>
<summary><b>ğŸ”´ Loss is NaN or Infinite</b></summary>

**Causes:**

- Learning rate too high
- Input data contains NaN/Infinity
- Numerical overflow

**Solutions:**

```typescript
// Reduce learning rate
const model = new ConvolutionalRegression({
  learningRate: 0.0001, // 10x smaller
  epsilon: 1e-7, // Larger epsilon for stability
});

// Validate input data
function validateData(data: FitInput): boolean {
  for (const row of data.xCoordinates) {
    if (row.some((x) => !isFinite(x))) return false;
  }
  return true;
}
```

</details>

<details>
<summary><b>ğŸŸ¡ Loss Not Decreasing</b></summary>

**Causes:**

- Learning rate too low
- Model too simple for data
- Data not properly formatted

**Solutions:**

```typescript
// Increase learning rate
const model = new ConvolutionalRegression({
  learningRate: 0.005, // Increase
  warmupSteps: 50, // Shorter warmup
});

// Or increase model capacity
const biggerModel = new ConvolutionalRegression({
  hiddenLayers: 4,
  convolutionsPerLayer: 128,
});
```

</details>

<details>
<summary><b>ğŸŸ¡ High Variance in Predictions</b></summary>

**Causes:**

- Insufficient training data
- High noise in data
- Model overfitting

**Solutions:**

```typescript
const model = new ConvolutionalRegression({
  regularizationStrength: 1e-3, // Increase regularization
  outlierThreshold: 2.5, // More aggressive outlier handling
  hiddenLayers: 1, // Simpler model
});
```

</details>

<details>
<summary><b>ğŸŸ¢ Frequent Drift Detection</b></summary>

**Causes:**

- adwinDelta too small
- Legitimately changing data distribution

**Solutions:**

```typescript
// If false positives:
const model = new ConvolutionalRegression({
  adwinDelta: 0.01, // Less sensitive
});

// If legitimate drift - embrace it:
function handleDrift(result: FitResult) {
  if (result.driftDetected) {
    // Drift is expected, model adapts automatically
    console.log("Distribution shift detected and handled");
  }
}
```

</details>

---

## ğŸ“ˆ Performance Tips

### Memory Optimization

```typescript
// Use smaller model for memory-constrained environments
const lightweightModel = new ConvolutionalRegression({
  hiddenLayers: 1,
  convolutionsPerLayer: 16,
  kernelSize: 3,
});

// Approximate memory usage:
// Parameters â‰ˆ hiddenLayers Ã— convolutionsPerLayerÂ² Ã— kernelSize Ã— 8 bytes
// Example: 2 Ã— 32Â² Ã— 3 Ã— 8 = ~49KB for weights alone
```

### Training Speed Optimization

```typescript
// Batch processing for speed
const BATCH_SIZE = 32;

for (let i = 0; i < data.length; i += BATCH_SIZE) {
  const batch = {
    xCoordinates: data.xCoordinates.slice(i, i + BATCH_SIZE),
    yCoordinates: data.yCoordinates.slice(i, i + BATCH_SIZE),
  };
  model.fitOnline(batch);
}
```

### Prediction Performance

```typescript
// Cache predictions when possible
const predictionCache = new Map<string, PredictionResult>();

function getCachedPrediction(
  model: ConvolutionalRegression,
  steps: number,
): PredictionResult {
  const key = `${model.getModelSummary().sampleCount}-${steps}`;

  if (!predictionCache.has(key)) {
    predictionCache.set(key, model.predict(steps));
  }

  return predictionCache.get(key)!;
}
```

---

## ğŸ“œ License

MIT Â© 2025 Henrique Emanoel Viana

---

<div align="center">

**Built with â¤ï¸ for the machine learning community**

[â¬† Back to Top](#-convolutionalregression)

</div>
